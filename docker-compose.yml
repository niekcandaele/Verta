services:
  redis:
    image: redis:7-alpine
    container_name: verta-redis
    ports:
      - '6379:6379'
    volumes:
      - redis_data:/data
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  app:
    build:
      context: ./backend
      target: dev
    container_name: verta-app
    ports:
      - '25000:25000'
    volumes:
      - ./backend:/app
      - /app/node_modules
    env_file:
      - .env
    environment:
      - NODE_ENV=development
      - DOCKERIZED=true
      - PORT=25000
      - DATABASE_POOL_SIZE=10
      - LOG_LEVEL=debug
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ML_SERVICE_URL=http://ml-service:8000
    depends_on:
      redis:
        condition: service_healthy
    command: npm run dev
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      target: dev
    container_name: verta-frontend
    ports:
      - '3000:3000'
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_TENANT_SLUG=${TEST_DISCORD_TENANT_SLUG}
    depends_on:
      - app
    command: npm run dev
    restart: unless-stopped

  ml-service:
    build:
      context: ./python-ml-service
    container_name: verta-ml-service
    ports:
      - '8000:8000'
    volumes:
      - ./python-ml-service:/app
    environment:
      - ML_SERVICE_DEBUG=${ML_SERVICE_DEBUG:-false}
      - ADMIN_API_KEY=${ADMIN_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - ML_SERVICE_WORKERS=1
      - ML_SERVICE_MODEL_CACHE_DIR=/models
    mem_limit: 6g
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8000/health']
      interval: 60s
      timeout: 60s
      start_period: 120s
      retries: 5
    restart: unless-stopped

volumes:
  redis_data:
